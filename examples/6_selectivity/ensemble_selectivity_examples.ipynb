{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial script for using the ensemble and selectivity maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit WARNING: [12:12:21] Enabling RDKit 2019.09.1 jupyter extensions\n"
     ]
    }
   ],
   "source": [
    "from hotspots.hs_ensembles import EnsembleResult, SelectivityResult\n",
    "from hotspots.hs_io import HotspotReader, HotspotWriter\n",
    "from hotspots.grid_extension import _GridEnsemble\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What do the ensemble maps settings mean?\n",
    "\n",
    "1. How ensemble maps are put together:\n",
    "\n",
    "![Flowchart for compiling the ensemble maps](./notebook_images/ensemble_maps_method.png)\n",
    "\n",
    "2. Verbose description of the parameters:\n",
    "\n",
    "\n",
    " - Frequency: ((number of times score observed at point)/ (number of maps in ensemble))*100\n",
    "   - For the polar maps, using a frequency threshold is used to remove artefacts of the alignment and \"noisy\" hotspots that are unlikely to contribute to the binding. For the apolar maps, the default frequency threshold is 0 (meaning to take into account all points), as these effects affect them less due to their larger volume and lack of orientation dependence.\n",
    "        \n",
    " - Combine mode: \n",
    "   - To calculate the ensemble maps, the algorithm takes the median (or mean, or max)of the nonzero values for each point in the polar maps that passes the frequency threshold. For the apolar maps, the default is to take the median (or other combine_mode) of all values, including zeros.\n",
    "        \n",
    "   - The combine_mode parameter controls how the information at each point is combined. Currently, the default is to take the median (with some modifications for the polar maps), but the 'mean' and 'max' modes could also be useful for exploratory work. \n",
    "            \n",
    "            \n",
    "* Note: Ensemble maps have not been tested with the positive and negative probes, although the option has been included here to allow exploration and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up parameters for the Ensemble Maps. Shown below are the default values, but the ensemble_settings allow for tweaking them.\n",
    "\n",
    "ensemble_settings= EnsembleResult.Settings()\n",
    "# Take the median value across the ensemble at each point in space\n",
    "ensemble_settings.combine_mode = 'median'\n",
    "\n",
    "# Include all points in the apolar maps\n",
    "ensemble_settings.apolar_frequency_threshold = 0.0\n",
    "\n",
    "# For the polar maps, use only points with nonzero scores in over 20% of the ensemble.\n",
    "ensemble_settings.polar_frequency_threshold = 20.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### * Note: The protein models used to calculate the input hotspot results for both the ensemble and selectivity maps need to have been aligned at the binding site of interest prior to the hotspots calculation. This can be done through the CCDC API, as described [here]( https://downloads.ccdc.cam.ac.uk/documentation/API/descriptive_docs/protein.html#superposing-protein-chains-and-binding-sites)\n",
    "\n",
    "\n",
    "Below is an example for calculating ensemble maps from a set of pre-calculated hotspot results for p38alpha kinase. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making the common grids\n",
      "Stared making arrays\n",
      "GridEnsemble complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mihaela/miniconda3/envs/hots_py3/lib/python3.7/site-packages/numpy/lib/nanfunctions.py:1115: RuntimeWarning: All-NaN slice encountered\n",
      "  overwrite_input=overwrite_input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "donor (223, 201, 225)\n",
      "Making the common grids\n",
      "Stared making arrays\n",
      "GridEnsemble complete\n",
      "acceptor (223, 201, 225)\n",
      "Making the common grids\n",
      "Stared making arrays\n",
      "GridEnsemble complete\n",
      "apolar (223, 201, 225)\n",
      "10\n",
      "14\n",
      "17\n"
     ]
    }
   ],
   "source": [
    "on_target = \"p38alpha\"\n",
    "\n",
    "# Load the pre-aligned, pre-calculated results:\n",
    "target_paths = list(Path(f\"{on_target}\").glob('*/fullsize_hotspots_3000/out.zip'))\n",
    "\n",
    "# Create the EnsembleResult object\n",
    "ensemble = EnsembleResult(hs_results_list=[HotspotReader(p).read() for p in target_paths],\n",
    "                                    ensemble_id=on_target,\n",
    "                                    settings=ensemble_settings)\n",
    "\n",
    "# Calculate the ensemble maps. This can be memory-intensive with large or many grids.\n",
    "ensemble.make_ensemble_maps(save_grid_ensembles=True)\n",
    "\n",
    "# Save the ensemble maps as a hotspots.Results object\n",
    "with HotspotWriter(f\"ensemble_{on_target}\", grid_extension=\".ccp4\", zip_results=False) as w:\n",
    "    w.write(ensemble.ensemble_hotspot_result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The EnsembleResult object compiles ensemble maps from a list of hotspot results. If the input grids are not the same size, they will be converted to the same size and coordinates via the hotspots.grid_extension.Grid.common_grid() method. The EnsembleResult can keep track of which grid belongs to which hotspot result. It identifies the hotspot results via the identifier of the protein in the input hotspot result (hs_result.protein.identifier). Usually, this is set automatically when reading in the PDB file, but can also be modified manually.\n",
    "\n",
    "Grids for each probe type are converted into numpy arrays and stacked into a hotspots.grid_extension.\\_GridEnsemble object, which is a wrapper around the 4D numpy array that holds the ensemble information for that probe type. Saving the grid ensembles generated in EnsembleResult.make_ensemble_maps() takes up extra memory, but allows for more detailed analysis.\n",
    "\n",
    "For example, let's see which structures in the ensemble contribute to one of the hotspot features in the acceptor ensemble map:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Structure: 2y8o.A, points in cluster: 23\n",
      "Structure: 1bl6.A, points in cluster: 10\n",
      "Structure: 1w84.A, points in cluster: 18\n",
      "Structure: 1wbo.A, points in cluster: 13\n",
      "Structure: 1w7h.A, points in cluster: 11\n"
     ]
    }
   ],
   "source": [
    "# Find hotspot features in the acceptor maps:\n",
    "p38_ensemble_acceptor_grid = ensemble.ensemble_hotspot_result.super_grids['acceptor']\n",
    "p38_acceptor_gridensemble = ensemble.grid_ensembles['acceptor']\n",
    "\n",
    "# Convert into numpy array:\n",
    "p38_ensemble_acceptor_array = _GridEnsemble.array_from_grid(p38_ensemble_acceptor_grid)\n",
    "\n",
    "# Find the hotspot features using HDBSCAN\n",
    "p38_ensemble_acceptor_clusters = _GridEnsemble.HDBSCAN_cluster(p38_ensemble_acceptor_array,\n",
    "                                                              min_cluster_size=7)\n",
    "\n",
    "# Let's see which structures contribute to cluster 24:\n",
    "contribs = p38_acceptor_gridensemble.get_contributing_maps(p38_ensemble_acceptor_clusters)[24]\n",
    "\n",
    "for c in contribs:\n",
    "    print(f\"Structure: {ensemble.index_dict[c[0]]}, points in cluster: {c[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the selectivity maps:\n",
    "\n",
    "Similar to the ensemble maps, selectivity maps are calculated by a SelectivityResult object, which takes hotspot results as input. Currently, it can only compare two results at a time, but functionality to compare more results is in the works.\n",
    "\n",
    "Like the ensemble maps, parameters for the selectivity maps can be set via a SelectivityResult.Settings() instance.\n",
    "\n",
    "Selectivity map parameters:\n",
    "\n",
    "![Flowchart for compiling the selectivity maps](./notebook_images/selectivity_maps_method.png)\n",
    "\n",
    "Feature detection in the selectivity maps is performed using the HDBSCAN algorithm\n",
    "\n",
    "- minimal_cluster_score (float): the minimal score needed for a cluster to be considered selective\n",
    "\n",
    "            \n",
    "- cluster_distance_cutoff (float): How far away a selective cluster can be from another selective cluster in the off-target  map (in angstroms). Some dependence on flexibility of binding site. Usually between 1.5 and 3.0\n",
    "\n",
    "            \n",
    "- apolar_percentile_threshold (float): If specified, only takes the top percentile of points specified in the difference map. Useful for clustering in the apolar maps, as they tend to be densely populated with low-scoring values\n",
    "\n",
    "            \n",
    "- polar_percentile_threshold (float): If specified, only takes the top percentile of points specified in the difference map. Currently not used (i.e. defaults to 0).\n",
    "\n",
    "            \n",
    "- minimum_points_cluster_polar(int): Currently, HDBSCAN used for feature detection in the difference maps. This parameter corresponds to the \"min_cluster_size\" kwarg. Default value is 7 based on retrospective examples, but 5-10 range could be reasonable.\n",
    "\n",
    "                                                \n",
    "- minimum_points_cluster_apolar (int): The apolar maps tend to have larger clusters, so the minimum HDBSCAN cluster size is correspondingly larger (default: 27).\n",
    "\n",
    "\n",
    "Example: calculating selectivity maps for p38a over a related MAPK kinase, ERK2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input grids of different size. Converting to same coordinates.\n",
      "Input grids of different size. Converting to same coordinates.\n",
      "Input grids of different size. Converting to same coordinates.\n",
      "10\n",
      "14\n",
      "17\n"
     ]
    }
   ],
   "source": [
    "off_target = \"ERK2\"\n",
    "\n",
    "# To save some time, let's load a pre-calculated ensemble.\n",
    "off_target_ensemble_hotspot_result = HotspotReader(Path(f\"ensemble_{off_target}/out\")).read()\n",
    "\n",
    "selectivity_settings = SelectivityResult.Settings()\n",
    "\n",
    "# Kinases are pretty dynamic, so let's set the cluster_distance_cutoff a bit higher:\n",
    "selectivity_settings.cluster_distance_cutoff = 3.0\n",
    "\n",
    "p38alpha_over_ERK2 = SelectivityResult(target_result=ensemble.ensemble_hotspot_result,\n",
    "                                       other_result=off_target_ensemble_hotspot_result)\n",
    "p38alpha_over_ERK2.make_selectivity_maps()\n",
    "\n",
    "with HotspotWriter(f\"selectivity_{on_target}_over_{off_target}\",grid_extension=\".ccp4\", zip_results=False) as wr:\n",
    "    wr.write(p38alpha_over_ERK2.selectivity_result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
